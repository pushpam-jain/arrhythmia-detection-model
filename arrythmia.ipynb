{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734edcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbed204",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( r\"D:\\Internship\\Arythmia\\a-large-scale-12-lead-electrocardiogram-database-for-arrhythmia-study-1.0.0\\RECORDS\") as fp:  \n",
    "    lines = fp.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"D:/Internship/Arythmia/a-large-scale-12-lead-electrocardiogram-database-for-arrhythmia-study-1.0.0/\"\n",
    "records = []\n",
    "for file in lines:\n",
    "    file_path = path + file[:-1] + \"RECORDS\"\n",
    "    with open(file_path) as fp:\n",
    "        file_names = ((fp.readlines()))\n",
    "        for i in range(len(file_names)):\n",
    "            file_names[i] = path + file[:-1]+file_names[i] \n",
    "        records.append(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf592494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = records\n",
    "# records = r[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e88aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "from scipy.signal import detrend\n",
    "\n",
    "X1 = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(len(records)):\n",
    "    files = np.array(records[i])\n",
    "    for j in range(files.shape[0]):\n",
    "        file_path = files[j].replace(\"\\n\", \"\")\n",
    "        if '164889003' in open(file_path + \".hea\").read():\n",
    "            signal, meta_val = wfdb.rdsamp(file_path)\n",
    "            value = signal.T\n",
    "            ecg_signals = value\n",
    "\n",
    "            if not (np.any(np.isinf(ecg_signals)) or np.any(np.isnan(ecg_signals))):\n",
    "                filtered_ecg = detrend(ecg_signals)\n",
    "                X1.append(filtered_ecg)\n",
    "                y_data.append(1)\n",
    "            else:\n",
    "                print(f\"Skipping file with infinite/NaN values: {file_path}\")\n",
    "X1 = np.array(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b2a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(X1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c831e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('Atrial_Fibrillation_ECG_signal_1780_patients_X.npy', X1)\n",
    "# np.save('Atrial_Fibrillation_ECG_signal_1780_patients_y_data_1.npy', y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6712386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X3 = X1\n",
    "# X1 = shuffle(X1,random_state=42)[:1000]\n",
    "# y_data = y_data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89903e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Pushpam/Downloads/ptbxl_database.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8bf4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_file_names = []\n",
    "for i in range(len(df)):\n",
    "    if 'NORM' in df.loc[i,'scp_codes']:\n",
    "        healthy_file_names.append(df.loc[i,'filename_hr'])\n",
    "healthy_file_names = shuffle(np.array(healthy_file_names), random_state=42)[:5000]\n",
    "# y_data = np.array(y_data2)[:1000]\n",
    "print(healthy_file_names.shape)\n",
    "x = healthy_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6296a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import butter, filtfilt, detrend\n",
    "\n",
    "directory = 'D:/Internship/MIDataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1'\n",
    "X2 = []\n",
    "for itr in range(x.shape[0]):\n",
    "    record_name = str(x[itr])\n",
    "    \n",
    "    signal, meta_val = wfdb.rdsamp(directory + '/' + record_name)\n",
    "    value = signal.T\n",
    "    ecg_signals = value\n",
    "\n",
    "    X2.append(detrend(ecg_signals))\n",
    "    y_data.append(0)\n",
    "X2 = np.array(X2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba2e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('NORMAL_ECG_signal_5000_patients_X.npy', X2)\n",
    "# np.save('NORMAL_ECG_signal_5000_patients_y_data_0.npy', y_data[1780:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.load('Atrial_Fibrillation_ECG_signal_1780_patients_X.npy')\n",
    "y_data_1 = np.load('Atrial_Fibrillation_ECG_signal_1780_patients_y_data_1.npy')\n",
    "X2 = np.load('NORMAL_ECG_signal_5000_patients_X.npy')\n",
    "y_data_0 = np.load('NORMAL_ECG_signal_5000_patients_y_data_0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X1,X2),axis=0)\n",
    "y_data = np.concatenate((y_data_1,y_data_0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad3058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y_data = shuffle(X, y_data, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d71da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X is your array with shape (448, 12, 30000)\n",
    "xnew = []\n",
    "ynew = []\n",
    "patient_ids = []\n",
    "window_size = 1000  # Adjust the window size as needed\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(5):  # Divide into 30 parts\n",
    "        start = j * window_size\n",
    "        end = (j + 1) * window_size\n",
    "        xnew.append(X[i, :, start:end])\n",
    "        ynew.append(y_data[i])  # Assuming you have 'y_data' defined\n",
    "        patient_ids.append(i)\n",
    "\n",
    "# Convert lists to arrays\n",
    "xnew = np.array(xnew)\n",
    "ynew = np.array(ynew)\n",
    "patient_ids = np.array(patient_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f810ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad92c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rocket=Rocket()\n",
    "rocket=Rocket(num_kernels=1000)\n",
    "rocket.fit(xnew)\n",
    "xt=rocket.transform(xnew)\n",
    "\n",
    "xt2 = xt\n",
    "ynew2 = ynew\n",
    "patient_ids2 = patient_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('xt_1798+5000_windowed_1000_kernels.npy', xt)\n",
    "# np.save('ynew_1798+5000_windowed_1000_kernels.npy', ynew)\n",
    "# np.save('patient_ids_1798+5000_windowed_1000_kernels.npy', patient_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xt = np.load('xt_1798+5000_windowed_1000_kernels.npy')\n",
    "# ynew = np.load('ynew_1798+5000_windowed_1000_kernels.npy')\n",
    "# patient_ids = np.load('patient_ids_1798+5000_windowed_1000_kernels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt, ynew, patient_ids = shuffle(xt2, ynew2, patient_ids2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifierCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b2d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "sum_accuracy = 0\n",
    "sum_sensitivity = 0\n",
    "sum_specificity = 0\n",
    "sum_f1 = 0\n",
    "\n",
    "for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "    X_train, X_test = xt[train_idx], xt[test_idx]\n",
    "    y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    y_pred_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_pred_majority.append(majority_vote)\n",
    "\n",
    "    y_test_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_test_majority.append(majority_vote)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "    sum_accuracy += accuracy\n",
    "\n",
    "    print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "average_accuracy = sum_accuracy / 5\n",
    "\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421577d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 5\n",
    "unhealthy = 1780\n",
    "folds = 5\n",
    "\n",
    "unhealthy_x = xt2[:unhealthy*window]\n",
    "healthy_x = xt2[unhealthy*window:]\n",
    "unhealthy_y = ynew2[:unhealthy*window]\n",
    "healthy_y = ynew2[unhealthy*window:]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "\n",
    "gkf1 = GroupKFold(n_splits=folds)\n",
    "gkf2 = GroupKFold(n_splits=folds)\n",
    "\n",
    "sum_accuracy = 0\n",
    "sum_f1 = 0\n",
    "\n",
    "for train_idx1, test_idx1 in gkf1.split(xt2[:unhealthy*window], ynew2[:unhealthy*window], groups=patient_ids2[:unhealthy*window]):\n",
    "    sum_accuracy = 0\n",
    "    X_train1, X_test1 = xt2[train_idx1], xt2[test_idx1]\n",
    "    y_train1, y_test1 = ynew2[train_idx1], ynew2[test_idx1]\n",
    "\n",
    "    for train_idx2, test_idx2 in gkf2.split(xt2[unhealthy*window:], ynew2[unhealthy*window:], groups=patient_ids2[unhealthy*window:]):\n",
    "        X_train2, X_test2 = healthy_x[train_idx2], healthy_x[test_idx2]\n",
    "        y_train2, y_test2 = healthy_y[train_idx2], healthy_y[test_idx2]\n",
    "\n",
    "        X_train = np.concatenate((X_train1, X_train2), axis=0) \n",
    "        X_test = np.concatenate((X_test1, X_test2), axis=0) \n",
    "\n",
    "        y_train = np.concatenate((y_train1, y_train2), axis=0) \n",
    "        y_test = np.concatenate((y_test1, y_test2), axis=0)\n",
    "        \n",
    "        classifier = SGDClassifier()\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        y_pred_majority = []\n",
    "        for i in range(0, y_pred.shape[0], window):\n",
    "            majority_vote = np.bincount(y_pred[i:i+window]).argmax()\n",
    "            y_pred_majority.append(majority_vote)\n",
    "\n",
    "        y_test_majority = []\n",
    "        for i in range(0, y_test.shape[0], window):\n",
    "            majority_vote = np.bincount(y_test[i:i+window]).argmax()\n",
    "            y_test_majority.append(majority_vote)\n",
    "\n",
    "        accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "        sum_accuracy += accuracy\n",
    "\n",
    "        print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    average_accuracy = sum_accuracy / folds\n",
    "    print(\"Average Accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 8\n",
    "# unhealthy = 460\n",
    "# folds = 3\n",
    "\n",
    "# unhealthy_x = xt[:unhealthy*window]\n",
    "# healthy_x = xt[unhealthy*window:]\n",
    "# unhealthy_y = ynew[:unhealthy*window]\n",
    "# healthy_y = ynew[unhealthy*window:]\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# import numpy as np\n",
    "\n",
    "# gkf1 = GroupKFold(n_splits=folds)\n",
    "# gkf2 = GroupKFold(n_splits=folds)\n",
    "\n",
    "# sum_accuracy = 0\n",
    "# sum_sensitivity = 0\n",
    "# sum_specificity = 0\n",
    "# sum_f1 = 0\n",
    "\n",
    "# # for train_idx1, test_idx1,train_idx2, test_idx2  in gkf1.split(xt[:800*5], ynew[:800*5], groups=patient_ids[:800*5]),gkf2.split(xt[800*5:], ynew[800*5:], groups=patient_ids[800*5:]):\n",
    "# for train_idx1, test_idx1  in gkf1.split(xt[:unhealthy*window], ynew[:unhealthy*window], groups=patient_ids[:unhealthy*window]):\n",
    "#     sum_accuracy = 0\n",
    "#     X_train1, X_test1 = xt.iloc[train_idx1], xt.iloc[test_idx1]\n",
    "#     y_train1, y_test1 = ynew[train_idx1], ynew[test_idx1]\n",
    "\n",
    "#     for train_idx2, test_idx2  in gkf2.split(xt[unhealthy*window:], ynew[unhealthy*window:], groups=patient_ids[unhealthy*window:]):\n",
    "#         X_train2, X_test2 = healthy_x.iloc[train_idx2], healthy_x.iloc[test_idx2]\n",
    "#         y_train2, y_test2 = healthy_y[train_idx2], healthy_y[test_idx2]\n",
    "\n",
    "#         X_train = np.concatenate((X_train1, X_train2), axis=0) \n",
    "#         X_test = np.concatenate((X_test1, X_test2), axis=0) \n",
    "\n",
    "#         y_train = np.concatenate((y_train1, y_train2), axis=0) \n",
    "#         y_test = np.concatenate((y_test1, y_test2), axis=0)\n",
    "        \n",
    "#     # for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "#     #     X_train, X_test = xt.iloc[train_idx], xt.iloc[test_idx]\n",
    "#     #     y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "#         classifier = SGDClassifier()\n",
    "#         classifier.fit(X_train, y_train)\n",
    "\n",
    "#         y_pred = classifier.predict(X_test)\n",
    "        \n",
    "#         y_pred_majority = []\n",
    "#         for i in range(0, y_pred.shape[0], window):\n",
    "#             majority_vote = np.bincount(y_pred[i:i+window]).argmax()\n",
    "#             y_pred_majority.append(majority_vote)\n",
    "\n",
    "#         y_test_majority = []\n",
    "#         for i in range(0, y_test.shape[0], window):\n",
    "#             majority_vote = np.bincount(y_test[i:i+window]).argmax()\n",
    "#             y_test_majority.append(majority_vote)\n",
    "\n",
    "#         accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "#         sum_accuracy += accuracy\n",
    "\n",
    "#     #     tn, fp, fn, tp = confusion_matrix(y_test_majority, y_pred_majority).ravel()\n",
    "\n",
    "#     #     sensitivity = tp / (tp + fn)\n",
    "#     #     specificity = tn / (tn + fp)\n",
    "#     #     f1 = f1_score(y_test_majority, y_pred_majority)\n",
    "\n",
    "#     #     sum_sensitivity += sensitivity\n",
    "#     #     sum_specificity += specificity\n",
    "#     #     sum_f1 += f1\n",
    "\n",
    "#         print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "#         print(\"Accuracy:\", accuracy)\n",
    "#     #     print(\"Sensitivity:\", sensitivity)\n",
    "#     #     print(\"Specificity:\", specificity)\n",
    "#     #     print(\"F1-Score:\", f1)\n",
    "#     #     print()\n",
    "\n",
    "#     average_accuracy = sum_accuracy / folds\n",
    "#     # average_sensitivity = sum_sensitivity / 5\n",
    "#     # average_specificity = sum_specificity / 5\n",
    "#     # average_f1 = sum_f1 / 5\n",
    "\n",
    "#     print(\"Average Accuracy:\", average_accuracy)\n",
    "#     # print(\"Average Sensitivity:\", average_sensitivity)\n",
    "#     # print(\"Average Specificity:\", average_specificity)\n",
    "#     # print(\"Average F1-Score:\", average_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f757f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "# from sktime.transformations.panel.rocket import Rocket\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.linear_model import SGDClassifier, RidgeClassifierCV\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.preprocessing import scale\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(xt, y_data,\n",
    "#                                                     test_size=0.25,\n",
    "#                                                     random_state=42)\n",
    "\n",
    "# classifier=SGDClassifier()\n",
    "# classifier.fit(X_train,y_train)\n",
    "\n",
    "# ypred=classifier.predict(X_test)\n",
    "\n",
    "# print(confusion_matrix(y_test,ypred))\n",
    "# print(accuracy_score(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3fcfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from biosppy.signals import ecg\n",
    "\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import butter, filtfilt, detrend\n",
    "\n",
    "# record_name = files_unhealthy[0].replace(\"\\n\", \"\")\n",
    "\n",
    "path = 'C:\\\\Users\\\\Pushpam\\\\Downloads\\\\'\n",
    "\n",
    "\n",
    "record_name = 'JS00001'\n",
    "\n",
    "# # Load the ECG record\n",
    "# record = wfdb.rdrecord(path + record_name)\n",
    "\n",
    "# # Extract the ECG signal\n",
    "# ecg_signal = record.p_signal[:, 5] \n",
    "\n",
    "# # Perform baseline wander removal\n",
    "# filtered_ecg = signal.detrend(ecg_signal)\n",
    "# filtered_ecg=filtered_ecg[:10000]\n",
    "# # Plot the ECG signal with detected R-peaks\n",
    "\n",
    "signal, meta_val = wfdb.rdsamp(path + record_name)\n",
    "value = signal.T\n",
    "ecg_signals = value\n",
    "\n",
    "filtered_ecg =X[700,3,:2000]#(detrend(ecg_signals))[2,:]\n",
    "\n",
    "# print(filtered_ecg)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(np.arange(len(filtered_ecg)) / 1000, filtered_ecg, 'b')\n",
    "# plt.plot(qrs_inds / record.fs, filtered_ecg[qrs_inds], 'ro', markersize=4)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dfaee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
