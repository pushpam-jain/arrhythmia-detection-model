{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "734edcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05552a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 = np.load('Atrial_Fibrillation_ECG_signal_1780_patients_X.npy')\n",
    "y_data_1 = np.load('Atrial_Fibrillation_ECG_signal_1780_patients_y_data_1.npy')\n",
    "# X2 = np.load('NORMAL_ECG_signal_5000_patients_X.npy')\n",
    "y_data_0 = np.load('NORMAL_ECG_signal_5000_patients_y_data_0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8328b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.concatenate((X1,X2),axis=0)\n",
    "y_data = np.concatenate((y_data_1,y_data_0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad3058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y_data = shuffle(X, y_data, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b06f9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "xnew = []\n",
    "ynew = []\n",
    "patient_ids = []\n",
    "window_size = 1000  \n",
    "\n",
    "for i in range(y_data.shape[0]):\n",
    "    for j in range(5):  \n",
    "#         start = j * window_size\n",
    "#         end = (j + 1) * window_size\n",
    "#         xnew.append(X[i, :, start:end])\n",
    "        ynew.append(y_data[i]) \n",
    "        patient_ids.append(i)\n",
    "\n",
    "# xnew = np.array(xnew)\n",
    "ynew = np.array(ynew)\n",
    "patient_ids = np.array(patient_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6ef741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import coherence\n",
    "from glob import glob\n",
    "import scipy.io as sio\n",
    "import scipy.signal as sig\n",
    "from scipy.signal import coherence, hilbert \n",
    "\n",
    "# mae_matrices_list = []\n",
    "# rmse_matrices_list = []\n",
    "cross_corr_matrices_list = []\n",
    "coherence_matrices_list = []\n",
    "pli_matrices_list = []\n",
    "plv_matrices_list = []\n",
    "\n",
    "for patient_data in xnew:\n",
    "    cross_corr_matrix = np.zeros((12, 12))\n",
    "#     mae_matrix = np.zeros((12, 12))\n",
    "#     rmse_matrix = np.zeros((12, 12))\n",
    "    coherence_matrix = np.zeros((12, 12))\n",
    "    pli_matrix = np.zeros((12, 12))\n",
    "    plv_matrix = np.zeros((12, 12))\n",
    "\n",
    "    \n",
    "    for i in range(12):\n",
    "        for j in range(i, 12):\n",
    "            lead_i = patient_data[i]\n",
    "            lead_j = patient_data[j]\n",
    "            \n",
    "            cross_corr = np.corrcoef(lead_i, lead_j)[0, 1]\n",
    "            \n",
    "#             mae = np.mean(np.abs(lead_i - lead_j))\n",
    "#             rmse = np.sqrt(np.mean((lead_i - lead_j) ** 2))\n",
    "            \n",
    "            f, coh = coherence(lead_i, lead_j)  \n",
    "            coherence_value = np.mean(coh)  # Storing the average coherence value\n",
    "            \n",
    "            \n",
    "            analytic_i = hilbert(lead_i)\n",
    "            analytic_j = hilbert(lead_j)\n",
    "            \n",
    "            phase_i = np.angle(analytic_i)\n",
    "            phase_j = np.angle(analytic_j)\n",
    "                    \n",
    "            phase_diff = phase_i - phase_j\n",
    "              \n",
    "            pli = np.abs(np.mean(np.sign(np.sin(phase_diff))))\n",
    "               \n",
    "            plv = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "            \n",
    "#             mae_matrix[i, j] = mae\n",
    "#             mae_matrix[j, i] = mae\n",
    "            \n",
    "#             rmse_matrix[i, j] = rmse\n",
    "#             rmse_matrix[j, i] = rmse\n",
    "\n",
    "\n",
    "            cross_corr_matrix[i, j] = cross_corr\n",
    "            cross_corr_matrix[j, i] = cross_corr\n",
    "        \n",
    "            coherence_matrix[i, j] = coherence_value\n",
    "            coherence_matrix[j, i] = coherence_value    \n",
    "            \n",
    "            pli_matrix[i, j] = pli\n",
    "            pli_matrix[j, i] = pli\n",
    "            \n",
    "            plv_matrix[i, j] = plv\n",
    "            plv_matrix[j, i] = plv\n",
    "    \n",
    "    \n",
    "    cross_corr_matrices_list.append(cross_corr_matrix)  \n",
    "#     mae_matrices_list.append(mae_matrix)\n",
    "#     rmse_matrices_list.append(rmse_matrix)  \n",
    "    coherence_matrices_list.append(coherence_matrix)\n",
    "    pli_matrices_list.append(pli_matrix)\n",
    "    plv_matrices_list.append(plv_matrix)\n",
    "    \n",
    "def create_K(A_i, B_i, C_i, D_i):\n",
    "    top_row = np.concatenate((A_i, B_i), axis=1)\n",
    "    bottom_row = np.concatenate((C_i, D_i), axis=1)\n",
    "    return np.concatenate((top_row, bottom_row), axis=0)\n",
    "\n",
    "K_matrices=[]\n",
    "for i in range(xnew.shape[0]):\n",
    "    K_i = create_K(cross_corr_matrices_list[i], coherence_matrices_list[i], pli_matrices_list[i], plv_matrices_list[i])\n",
    "    K_matrices.append(K_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc77b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('cross_corr_matrices_list_1780+5000_windowed5_not_random.npy', cross_corr_matrices_list)\n",
    "# np.save('coherence_matrices_list_1780+5000_windowed5_not_random.npy', coherence_matrices_list)\n",
    "# np.save('pli_matrices_list_1780+5000_windowed5_not_random.npy', pli_matrices_list)\n",
    "# np.save('plv_matrices_list_1780+5000_windowed5_not_random.npy', plv_matrices_list)\n",
    "# np.save('K_matrices_1780+5000_windowed5_not_random.npy', K_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8bcc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_corr_matrices_list = np.load('cross_corr_matrices_list_1780+5000_windowed5_not_random.npy', allow_pickle=True)\n",
    "coherence_matrices_list = np.load('coherence_matrices_list_1780+5000_windowed5_not_random.npy', allow_pickle=True)\n",
    "pli_matrices_list = np.load('pli_matrices_list_1780+5000_windowed5_not_random.npy', allow_pickle=True)\n",
    "plv_matrices_list = np.load('plv_matrices_list_1780+5000_windowed5_not_random.npy', allow_pickle=True)\n",
    "K_matrices = np.load('K_matrices_1780+5000_windowed5_not_random.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e945a04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33900, 576)\n"
     ]
    }
   ],
   "source": [
    "t = np.array(K_matrices).reshape(K_matrices.shape[0],-1)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0a1f5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "678/678 [==============================] - 6s 9ms/step - loss: 0.2734 - accuracy: 0.8801 - val_loss: 0.0972 - val_accuracy: 0.9677\n",
      "Epoch 2/3\n",
      "678/678 [==============================] - 6s 9ms/step - loss: 0.1275 - accuracy: 0.9501 - val_loss: 0.2259 - val_accuracy: 0.9226\n",
      "Epoch 3/3\n",
      "678/678 [==============================] - 6s 9ms/step - loss: 0.1022 - accuracy: 0.9605 - val_loss: 0.0305 - val_accuracy: 0.9878\n",
      "212/212 [==============================] - 1s 2ms/step\n",
      "[[994   7]\n",
      " [ 16 339]]\n",
      "Accuracy: 0.9830383480825958\n",
      "Sensitivity: 0.9549295774647887\n",
      "Specificity: 0.993006993006993\n",
      "Epoch 1/3\n",
      "678/678 [==============================] - 6s 9ms/step - loss: 0.2670 - accuracy: 0.8825 - val_loss: 0.0418 - val_accuracy: 0.9851\n",
      "Epoch 2/3\n",
      "678/678 [==============================] - 6s 9ms/step - loss: 0.1281 - accuracy: 0.9507 - val_loss: 0.0380 - val_accuracy: 0.9871\n",
      "Epoch 3/3\n",
      "678/678 [==============================] - 6s 9ms/step - loss: 0.1034 - accuracy: 0.9600 - val_loss: 0.0384 - val_accuracy: 0.9858\n",
      "212/212 [==============================] - 0s 2ms/step\n",
      "[[997   3]\n",
      " [ 26 330]]\n",
      "Accuracy: 0.9786135693215339\n",
      "Sensitivity: 0.9269662921348315\n",
      "Specificity: 0.997\n",
      "Epoch 1/3\n",
      "678/678 [==============================] - 7s 9ms/step - loss: 0.2877 - accuracy: 0.8699 - val_loss: 0.0952 - val_accuracy: 0.9585\n",
      "Epoch 2/3\n",
      "678/678 [==============================] - 6s 9ms/step - loss: 0.1299 - accuracy: 0.9508 - val_loss: 0.0510 - val_accuracy: 0.9814\n",
      "Epoch 3/3\n",
      "678/678 [==============================] - 6s 9ms/step - loss: 0.1009 - accuracy: 0.9623 - val_loss: 0.0844 - val_accuracy: 0.9694\n",
      "212/212 [==============================] - 1s 2ms/step\n",
      "[[982  18]\n",
      " [  7 349]]\n",
      "Accuracy: 0.9815634218289085\n",
      "Sensitivity: 0.9803370786516854\n",
      "Specificity: 0.982\n",
      "Epoch 1/3\n",
      "678/678 [==============================] - 7s 9ms/step - loss: 0.2802 - accuracy: 0.8772 - val_loss: 0.1329 - val_accuracy: 0.9436\n",
      "Epoch 2/3\n",
      "678/678 [==============================] - 6s 9ms/step - loss: 0.1294 - accuracy: 0.9500 - val_loss: 0.0531 - val_accuracy: 0.9801\n",
      "Epoch 3/3\n",
      "678/678 [==============================] - 6s 9ms/step - loss: 0.1020 - accuracy: 0.9604 - val_loss: 0.0755 - val_accuracy: 0.9699\n",
      "212/212 [==============================] - 0s 2ms/step\n",
      "[[984  16]\n",
      " [  6 350]]\n",
      "Accuracy: 0.9837758112094396\n",
      "Sensitivity: 0.9831460674157303\n",
      "Specificity: 0.984\n",
      "Epoch 1/3\n",
      "678/678 [==============================] - 7s 10ms/step - loss: 0.3135 - accuracy: 0.8525 - val_loss: 0.1051 - val_accuracy: 0.9594\n",
      "Epoch 2/3\n",
      "678/678 [==============================] - 7s 11ms/step - loss: 0.1328 - accuracy: 0.9487 - val_loss: 0.0575 - val_accuracy: 0.9806\n",
      "Epoch 3/3\n",
      "678/678 [==============================] - 7s 11ms/step - loss: 0.1020 - accuracy: 0.9619 - val_loss: 0.0892 - val_accuracy: 0.9624\n",
      "212/212 [==============================] - 1s 3ms/step\n",
      "[[982  17]\n",
      " [  9 348]]\n",
      "Accuracy: 0.9808259587020649\n",
      "Sensitivity: 0.9747899159663865\n",
      "Specificity: 0.982982982982983\n",
      "Average Accuracy: 0.9815634218289085\n",
      "Average Sensitivity: 0.9640337863266846\n",
      "Average Specificity: 0.9877979951979953\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D, AvgPool2D\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "sum_accuracy = 0\n",
    "sum_sensitivity = 0\n",
    "sum_specificity = 0\n",
    "\n",
    "for train_idx, test_idx in gkf.split(t, ynew, groups=patient_ids):\n",
    "    X_train, X_test = t[train_idx], t[test_idx]\n",
    "    y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(30, (3, 3), input_shape=(24, 24, 1)))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='BinaryCrossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=3,\n",
    "              verbose=1,\n",
    "              validation_split=0.2)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    y_pred = np.round(predictions).astype(int).transpose()\n",
    "    y_pred = y_pred[0]\n",
    "\n",
    "    y_pred_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_pred_majority.append(majority_vote)\n",
    "\n",
    "    y_test_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_test_majority.append(majority_vote)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "    sum_accuracy += accuracy\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_majority, y_pred_majority).ravel()\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    sum_sensitivity += sensitivity\n",
    "    sum_specificity += specificity\n",
    "\n",
    "    print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "\n",
    "average_accuracy = sum_accuracy / 5\n",
    "average_sensitivity = sum_sensitivity / 5\n",
    "average_specificity = sum_specificity / 5\n",
    "\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "print(\"Average Sensitivity:\", average_sensitivity)\n",
    "print(\"Average Specificity:\", average_specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b21c0935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000    1]\n",
      " [  61  294]]\n",
      "Accuracy: 0.9542772861356932\n",
      "Sensitivity: 0.828169014084507\n",
      "Specificity: 0.999000999000999\n",
      "[[994   6]\n",
      " [ 19 337]]\n",
      "Accuracy: 0.9815634218289085\n",
      "Sensitivity: 0.9466292134831461\n",
      "Specificity: 0.994\n",
      "[[987  13]\n",
      " [ 13 343]]\n",
      "Accuracy: 0.9808259587020649\n",
      "Sensitivity: 0.9634831460674157\n",
      "Specificity: 0.987\n",
      "[[994   6]\n",
      " [ 17 339]]\n",
      "Accuracy: 0.9830383480825958\n",
      "Sensitivity: 0.952247191011236\n",
      "Specificity: 0.994\n",
      "[[987  12]\n",
      " [ 11 346]]\n",
      "Accuracy: 0.9830383480825958\n",
      "Sensitivity: 0.969187675070028\n",
      "Specificity: 0.987987987987988\n",
      "Average Accuracy: 0.9765486725663717\n",
      "Average Sensitivity: 0.9319432479432666\n",
      "Average Specificity: 0.9923977973977974\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D, AvgPool2D\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "sum_accuracy = 0\n",
    "sum_sensitivity = 0\n",
    "sum_specificity = 0\n",
    "\n",
    "for train_idx, test_idx in gkf.split(t, ynew, groups=patient_ids):\n",
    "    X_train, X_test = t[train_idx], t[test_idx]\n",
    "    y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    y_pred_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_pred_majority.append(majority_vote)\n",
    "\n",
    "    y_test_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_test_majority.append(majority_vote)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "    sum_accuracy += accuracy\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_majority, y_pred_majority).ravel()\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    sum_sensitivity += sensitivity\n",
    "    sum_specificity += specificity\n",
    "\n",
    "    print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "\n",
    "average_accuracy = sum_accuracy / 5\n",
    "average_sensitivity = sum_sensitivity / 5\n",
    "average_specificity = sum_specificity / 5\n",
    "\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "print(\"Average Sensitivity:\", average_sensitivity)\n",
    "print(\"Average Specificity:\", average_specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cff30e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33900, 276)\n"
     ]
    }
   ],
   "source": [
    "def get_upper_triangular(matrix):\n",
    "    rows, cols = matrix.shape\n",
    "    upper_triangular = []\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(i + 1, cols):\n",
    "            upper_triangular.append(matrix[i, j])\n",
    "\n",
    "    return np.array(upper_triangular)\n",
    "t2 = []\n",
    "for i in range(t.shape[0]):\n",
    "    t2.append(get_upper_triangular(t[i]))\n",
    "t = np.array(t2)\n",
    "print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcb5c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.load('xt_1798+5000_windowed5_10000_kernels_not_random.npy')\n",
    "ynew = np.load('ynew_1798+5000_windowed5_10000_kernels_not_random.npy')\n",
    "patient_ids = np.load('patient_ids_1798+5000_windowed5_10000_kernels_not_random.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa5e62eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33900, 20000)\n",
      "(33900, 20276)\n"
     ]
    }
   ],
   "source": [
    "print(xt.shape)\n",
    "xt2 = np.concatenate((xt,t), axis=1)\n",
    "xt = xt2\n",
    "print(xt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8cba69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[999   2]\n",
      " [  8 347]]\n",
      "Accuracy: 0.9926253687315634\n",
      "Sensitivity: 0.9774647887323944\n",
      "Specificity: 0.998001998001998\n",
      "[[998   2]\n",
      " [ 12 344]]\n",
      "Accuracy: 0.9896755162241888\n",
      "Sensitivity: 0.9662921348314607\n",
      "Specificity: 0.998\n",
      "[[986  14]\n",
      " [  1 355]]\n",
      "Accuracy: 0.9889380530973452\n",
      "Sensitivity: 0.9971910112359551\n",
      "Specificity: 0.986\n",
      "[[983  17]\n",
      " [  2 354]]\n",
      "Accuracy: 0.9859882005899705\n",
      "Sensitivity: 0.9943820224719101\n",
      "Specificity: 0.983\n",
      "[[994   5]\n",
      " [  9 348]]\n",
      "Accuracy: 0.9896755162241888\n",
      "Sensitivity: 0.9747899159663865\n",
      "Specificity: 0.994994994994995\n",
      "Average Accuracy: 0.9893805309734514\n",
      "Average Sensitivity: 0.9820239746476214\n",
      "Average Specificity: 0.9919993985993987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "sum_accuracy = 0\n",
    "sum_sensitivity = 0\n",
    "sum_specificity = 0\n",
    "sum_f1 = 0\n",
    "\n",
    "for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "    X_train, X_test = xt[train_idx], xt[test_idx]\n",
    "    y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    y_pred_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_pred_majority.append(majority_vote)\n",
    "\n",
    "    y_test_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_test_majority.append(majority_vote)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "    sum_accuracy += accuracy\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_majority, y_pred_majority).ravel()\n",
    "\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    sum_sensitivity += sensitivity\n",
    "    sum_specificity += specificity\n",
    "\n",
    "    print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Sensitivity:\", sensitivity)\n",
    "    print(\"Specificity:\", specificity)\n",
    "\n",
    "average_accuracy = sum_accuracy / 5\n",
    "average_sensitivity = sum_sensitivity / 5\n",
    "average_specificity = sum_specificity / 5\n",
    "\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "print(\"Average Sensitivity:\", average_sensitivity)\n",
    "print(\"Average Specificity:\", average_specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f810ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad92c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rocket=Rocket()\n",
    "rocket=Rocket(num_kernels=2000)\n",
    "rocket.fit(xnew)\n",
    "xt=rocket.transform(xnew)\n",
    "\n",
    "xt2 = xt\n",
    "ynew2 = ynew\n",
    "patient_ids2 = patient_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('xt_1798+5000_windowed5_2000_kernels_not_random.npy', xt2)\n",
    "# np.save('ynew_1798+5000_windowed5_2000_kernels_not_random.npy', ynew2)\n",
    "# np.save('patient_ids_1798+5000_windowed5_2000_kernels_not_random.npy', patient_ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xt = np.load('xt_1798+5000_windowed5_2000_kernels_not_random.npy')\n",
    "# ynew = np.load('ynew_1798+5000_windowed5_2000_kernels_not_random.npy')\n",
    "# patient_ids = np.load('patient_ids_1798+5000_windowed5_2000_kernels_not_random.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt, ynew, patient_ids = shuffle(xt2, ynew2, patient_ids2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifierCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b2d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "sum_accuracy = 0\n",
    "sum_sensitivity = 0\n",
    "sum_specificity = 0\n",
    "sum_f1 = 0\n",
    "\n",
    "for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "    X_train, X_test = xt.iloc[train_idx], xt.iloc[test_idx]\n",
    "    y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    y_pred_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_pred[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_pred_majority.append(majority_vote)\n",
    "\n",
    "    y_test_majority = []\n",
    "    for patient_idx in np.unique(patient_ids[test_idx]):\n",
    "        segment_predictions = y_test[patient_ids[test_idx] == patient_idx]\n",
    "        majority_vote = np.bincount(segment_predictions).argmax()\n",
    "        y_test_majority.append(majority_vote)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "    sum_accuracy += accuracy\n",
    "\n",
    "    print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "average_accuracy = sum_accuracy / 5\n",
    "\n",
    "print(\"Average Accuracy:\", average_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95360f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 5\n",
    "unhealthy = 1780\n",
    "folds = 4\n",
    "\n",
    "unhealthy_x = xt2[:unhealthy*window]\n",
    "healthy_x = xt2[unhealthy*window:]\n",
    "unhealthy_y = ynew2[:unhealthy*window]\n",
    "healthy_y = ynew2[unhealthy*window:]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import numpy as np\n",
    "\n",
    "gkf1 = GroupKFold(n_splits=folds)\n",
    "gkf2 = GroupKFold(n_splits=folds)\n",
    "\n",
    "sum_accuracy = 0\n",
    "sum_f1 = 0\n",
    "\n",
    "for train_idx1, test_idx1 in gkf1.split(xt2[:unhealthy*window], ynew2[:unhealthy*window], groups=patient_ids2[:unhealthy*window]):\n",
    "    sum_accuracy = 0\n",
    "    X_train1, X_test1 = xt2.iloc[train_idx1], xt2.iloc[test_idx1]\n",
    "    y_train1, y_test1 = ynew2[train_idx1], ynew2[test_idx1]\n",
    "\n",
    "    for train_idx2, test_idx2 in gkf2.split(xt2[unhealthy*window:], ynew2[unhealthy*window:], groups=patient_ids2[unhealthy*window:]):\n",
    "        X_train2, X_test2 = healthy_x.iloc[train_idx2], healthy_x.iloc[test_idx2]\n",
    "        y_train2, y_test2 = healthy_y[train_idx2], healthy_y[test_idx2]\n",
    "\n",
    "        X_train = np.concatenate((X_train1, X_train2), axis=0) \n",
    "        X_test = np.concatenate((X_test1, X_test2), axis=0) \n",
    "\n",
    "        y_train = np.concatenate((y_train1, y_train2), axis=0) \n",
    "        y_test = np.concatenate((y_test1, y_test2), axis=0)\n",
    "        \n",
    "        classifier = SGDClassifier()\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        y_pred_majority = []\n",
    "        for i in range(0, y_pred.shape[0], window):\n",
    "            majority_vote = np.bincount(y_pred[i:i+window]).argmax()\n",
    "            y_pred_majority.append(majority_vote)\n",
    "\n",
    "        y_test_majority = []\n",
    "        for i in range(0, y_test.shape[0], window):\n",
    "            majority_vote = np.bincount(y_test[i:i+window]).argmax()\n",
    "            y_test_majority.append(majority_vote)\n",
    "\n",
    "        accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "        sum_accuracy += accuracy\n",
    "\n",
    "        print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "        print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    average_accuracy = sum_accuracy / folds\n",
    "    print(\"Average Accuracy:\", average_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window = 8\n",
    "# unhealthy = 460\n",
    "# folds = 3\n",
    "\n",
    "# unhealthy_x = xt[:unhealthy*window]\n",
    "# healthy_x = xt[unhealthy*window:]\n",
    "# unhealthy_y = ynew[:unhealthy*window]\n",
    "# healthy_y = ynew[unhealthy*window:]\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# import numpy as np\n",
    "\n",
    "# gkf1 = GroupKFold(n_splits=folds)\n",
    "# gkf2 = GroupKFold(n_splits=folds)\n",
    "\n",
    "# sum_accuracy = 0\n",
    "# sum_sensitivity = 0\n",
    "# sum_specificity = 0\n",
    "# sum_f1 = 0\n",
    "\n",
    "# # for train_idx1, test_idx1,train_idx2, test_idx2  in gkf1.split(xt[:800*5], ynew[:800*5], groups=patient_ids[:800*5]),gkf2.split(xt[800*5:], ynew[800*5:], groups=patient_ids[800*5:]):\n",
    "# for train_idx1, test_idx1  in gkf1.split(xt[:unhealthy*window], ynew[:unhealthy*window], groups=patient_ids[:unhealthy*window]):\n",
    "#     sum_accuracy = 0\n",
    "#     X_train1, X_test1 = xt.iloc[train_idx1], xt.iloc[test_idx1]\n",
    "#     y_train1, y_test1 = ynew[train_idx1], ynew[test_idx1]\n",
    "\n",
    "#     for train_idx2, test_idx2  in gkf2.split(xt[unhealthy*window:], ynew[unhealthy*window:], groups=patient_ids[unhealthy*window:]):\n",
    "#         X_train2, X_test2 = healthy_x.iloc[train_idx2], healthy_x.iloc[test_idx2]\n",
    "#         y_train2, y_test2 = healthy_y[train_idx2], healthy_y[test_idx2]\n",
    "\n",
    "#         X_train = np.concatenate((X_train1, X_train2), axis=0) \n",
    "#         X_test = np.concatenate((X_test1, X_test2), axis=0) \n",
    "\n",
    "#         y_train = np.concatenate((y_train1, y_train2), axis=0) \n",
    "#         y_test = np.concatenate((y_test1, y_test2), axis=0)\n",
    "        \n",
    "#     # for train_idx, test_idx in gkf.split(xt, ynew, groups=patient_ids):\n",
    "#     #     X_train, X_test = xt.iloc[train_idx], xt.iloc[test_idx]\n",
    "#     #     y_train, y_test = ynew[train_idx], ynew[test_idx]\n",
    "\n",
    "#         classifier = SGDClassifier()\n",
    "#         classifier.fit(X_train, y_train)\n",
    "\n",
    "#         y_pred = classifier.predict(X_test)\n",
    "        \n",
    "#         y_pred_majority = []\n",
    "#         for i in range(0, y_pred.shape[0], window):\n",
    "#             majority_vote = np.bincount(y_pred[i:i+window]).argmax()\n",
    "#             y_pred_majority.append(majority_vote)\n",
    "\n",
    "#         y_test_majority = []\n",
    "#         for i in range(0, y_test.shape[0], window):\n",
    "#             majority_vote = np.bincount(y_test[i:i+window]).argmax()\n",
    "#             y_test_majority.append(majority_vote)\n",
    "\n",
    "#         accuracy = accuracy_score(y_test_majority, y_pred_majority)\n",
    "#         sum_accuracy += accuracy\n",
    "\n",
    "#     #     tn, fp, fn, tp = confusion_matrix(y_test_majority, y_pred_majority).ravel()\n",
    "\n",
    "#     #     sensitivity = tp / (tp + fn)\n",
    "#     #     specificity = tn / (tn + fp)\n",
    "#     #     f1 = f1_score(y_test_majority, y_pred_majority)\n",
    "\n",
    "#     #     sum_sensitivity += sensitivity\n",
    "#     #     sum_specificity += specificity\n",
    "#     #     sum_f1 += f1\n",
    "\n",
    "#         print(confusion_matrix(y_test_majority, y_pred_majority))\n",
    "#         print(\"Accuracy:\", accuracy)\n",
    "#     #     print(\"Sensitivity:\", sensitivity)\n",
    "#     #     print(\"Specificity:\", specificity)\n",
    "#     #     print(\"F1-Score:\", f1)\n",
    "#     #     print()\n",
    "\n",
    "#     average_accuracy = sum_accuracy / folds\n",
    "#     # average_sensitivity = sum_sensitivity / 5\n",
    "#     # average_specificity = sum_specificity / 5\n",
    "#     # average_f1 = sum_f1 / 5\n",
    "\n",
    "#     print(\"Average Accuracy:\", average_accuracy)\n",
    "#     # print(\"Average Sensitivity:\", average_sensitivity)\n",
    "#     # print(\"Average Specificity:\", average_specificity)\n",
    "#     # print(\"Average F1-Score:\", average_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f757f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "# from sktime.transformations.panel.rocket import Rocket\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.linear_model import SGDClassifier, RidgeClassifierCV\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.preprocessing import scale\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(xt, y_data,\n",
    "#                                                     test_size=0.25,\n",
    "#                                                     random_state=42)\n",
    "\n",
    "# classifier=SGDClassifier()\n",
    "# classifier.fit(X_train,y_train)\n",
    "\n",
    "# ypred=classifier.predict(X_test)\n",
    "\n",
    "# print(confusion_matrix(y_test,ypred))\n",
    "# print(accuracy_score(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3fcfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from biosppy.signals import ecg\n",
    "\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import butter, filtfilt, detrend\n",
    "\n",
    "# record_name = files_unhealthy[0].replace(\"\\n\", \"\")\n",
    "\n",
    "path = 'C:\\\\Users\\\\Pushpam\\\\Downloads\\\\'\n",
    "\n",
    "\n",
    "record_name = 'JS00001'\n",
    "\n",
    "# # Load the ECG record\n",
    "# record = wfdb.rdrecord(path + record_name)\n",
    "\n",
    "# # Extract the ECG signal\n",
    "# ecg_signal = record.p_signal[:, 5] \n",
    "\n",
    "# # Perform baseline wander removal\n",
    "# filtered_ecg = signal.detrend(ecg_signal)\n",
    "# filtered_ecg=filtered_ecg[:10000]\n",
    "# # Plot the ECG signal with detected R-peaks\n",
    "\n",
    "signal, meta_val = wfdb.rdsamp(path + record_name)\n",
    "value = signal.T\n",
    "ecg_signals = value\n",
    "\n",
    "filtered_ecg =X[700,3,:2000]#(detrend(ecg_signals))[2,:]\n",
    "\n",
    "# print(filtered_ecg)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(np.arange(len(filtered_ecg)) / 1000, filtered_ecg, 'b')\n",
    "# plt.plot(qrs_inds / record.fs, filtered_ecg[qrs_inds], 'ro', markersize=4)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dfaee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
